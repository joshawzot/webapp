{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'core_post_processing_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Insert path to \"flint_mpw4_testing\\tests\\postprocess\" if using rwb_viewer notebook outside of this folder\u001b[39;00m\n\u001b[1;32m     12\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAdrienPierre\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mflint_mpw4_testing\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtests\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpostprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcore_post_processing_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcf\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcreate_and_upload_rwb_param\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcurp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'core_post_processing_functions'"
     ]
    }
   ],
   "source": [
    "# Jupyter notebook to pull rwb data and run analysis on it.\n",
    "# Ensure that you are connected to the Tetramem network to pull data.\n",
    "# fuck you\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os, re, math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import subprocess\n",
    "import json\n",
    "# Insert path to \"flint_mpw4_testing\\tests\\postprocess\" if using rwb_viewer notebook outside of this folder\n",
    "sys.path.insert(1, r\"C:\\Users\\AdrienPierre\\Documents\\flint_mpw4_testing\\tests\\postprocess\")\n",
    "import core_post_processing_functions as cf\n",
    "import create_and_upload_rwb_param as curp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example analysis of correlating pre-bake vs. post-bake metrics. The first half will look at IO-level correlations while the second half of teh analysis will explore bit-level correlations. It is highly recommended to install Data Wrangler extension in VS Code for easy viewing of pandas dataframes. After installing this extension a button called 'View data' should appear at the top bar of your jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. IO-level correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Pull all data from TT27\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rwb_pull \u001b[38;5;241m=\u001b[39m \u001b[43mcf\u001b[49m\u001b[38;5;241m.\u001b[39mrwb_fetch_data(regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTT27\u001b[39m\u001b[38;5;124m'\u001b[39m, regex_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDIE_ID\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Leave empty to pull all RWB data, takes longer time\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cf' is not defined"
     ]
    }
   ],
   "source": [
    "# Pull all data from TT27\n",
    "rwb_pull = cf.rwb_fetch_data(regex='TT27', regex_col='DIE_ID') # Leave empty to pull all RWB data, takes longer time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rwb_pull' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Determine which macros/IOs were baked\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m baked_tt27macroios \u001b[38;5;241m=\u001b[39m \u001b[43mrwb_pull\u001b[49m\u001b[38;5;241m.\u001b[39mloc[rwb_pull\u001b[38;5;241m.\u001b[39mRUN_NAME\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbake\u001b[39m\u001b[38;5;124m'\u001b[39m)][[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDIE_ID\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMACRO\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIO\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates() \u001b[38;5;66;03m# drop duplicates is to remove duplicate items after only keeping die, macro and IO columns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Determine which macros/IOs were cycled up to 100\u001b[39;00m\n\u001b[1;32m      5\u001b[0m cyc100_tt27macroios \u001b[38;5;241m=\u001b[39m rwb_pull\u001b[38;5;241m.\u001b[39mloc[rwb_pull\u001b[38;5;241m.\u001b[39mTEST_NAME\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m100cyc\u001b[39m\u001b[38;5;124m'\u001b[39m)][[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDIE_ID\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMACRO\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIO\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rwb_pull' is not defined"
     ]
    }
   ],
   "source": [
    "# Determine which macros/IOs were baked\n",
    "baked_tt27macroios = rwb_pull.loc[rwb_pull.RUN_NAME.str.contains('bake')][['DIE_ID','MACRO','IO']].drop_duplicates() # drop duplicates is to remove duplicate items after only keeping die, macro and IO columns\n",
    "\n",
    "# Determine which macros/IOs were cycled up to 100\n",
    "cyc100_tt27macroios = rwb_pull.loc[rwb_pull.TEST_NAME.str.contains('100cyc')][['DIE_ID','MACRO','IO']].drop_duplicates()\n",
    "\n",
    "# Find the intersection of the two\n",
    "RAC_tt27macroios = pd.merge(left=baked_tt27macroios, right=cyc100_tt27macroios, how='inner') # Use inner intersection (default) to keep common macros/IOs for these two conditions (baked and cycled)\n",
    "print(RAC_tt27macroios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rwb_pull' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Filter your pulled data to the found die by doing an inner merge\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rwb_RAC \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(left\u001b[38;5;241m=\u001b[39m\u001b[43mrwb_pull\u001b[49m, right\u001b[38;5;241m=\u001b[39mRAC_tt27macroios, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Print the unique TEST_NAMEs to sanity check\u001b[39;00m\n\u001b[1;32m      5\u001b[0m test_name_counts \u001b[38;5;241m=\u001b[39m rwb_RAC\u001b[38;5;241m.\u001b[39mTEST_NAME\u001b[38;5;241m.\u001b[39mvalue_counts() \u001b[38;5;66;03m# Value counts shows the number of rows for each unique value\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rwb_pull' is not defined"
     ]
    }
   ],
   "source": [
    "# Filter your pulled data to the found die by doing an inner merge\n",
    "rwb_RAC = pd.merge(left=rwb_pull, right=RAC_tt27macroios, how='inner')\n",
    "\n",
    "# Print the unique TEST_NAMEs to sanity check\n",
    "test_name_counts = rwb_RAC.TEST_NAME.value_counts() # Value counts shows the number of rows for each unique value\n",
    "print(test_name_counts.to_string()) # .to_string() is added at the end to enable full viewing of this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's only keep data for tests on all 32 measured IOs\n",
    "tests_of_interest = test_name_counts[test_name_counts >= 32].index.to_list()\n",
    "tests_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The TEST_NAME 'T0_read0' has 36 readouts even though there are only 32 IOs, let's find out where the redundancy in the data is\n",
    "rwb_T0debug = rwb_RAC.loc[rwb_RAC.TEST_NAME=='T0_read0']\n",
    "\n",
    "# Using Data Wranger to explore the data frame, we notice that all duplicate runs come from what looks like a validation run on IO0 before KPI called 'IO0preKPI'. TO be safe let's exclude IO0 from our study\n",
    "rwb_RAC = rwb_RAC.loc[~(rwb_RAC.IO==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The updated TEST_NAMEs are shown below\n",
    "test_name_counts = rwb_RAC.TEST_NAME.value_counts() # Value counts shows the number of rows for each unique value\n",
    "print(test_name_counts.to_string()) # .to_string() is added at the end to enable full viewing of this list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the dataset is cleaned up, let's start plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the NQ distributions, let's say we want to check out the 3 IOs with the best (widest) and worst (narrowest) T0 read window for Level 0/1 just to gauge the data.\n",
    "\n",
    "# Locate T0 readout and sort rows based on level0/1 windwo at 170PPM. Higher row index (further down the table) means worse window.\n",
    "rwb_T0_sorted_by_level01window = rwb_RAC.loc[rwb_RAC.TEST_NAME=='T0_read0'].sort_values(by='LEVEL_01_170PPM_ADCRWB', ascending=False)\n",
    "\n",
    "print('The best 3 IOs for LEVEL_01_170PPM_ADCRWB')\n",
    "cf.rwb_overlay_levels_nqplot(rwb_T0_sorted_by_level01window.iloc[:3], groupby_col='IO')\n",
    "\n",
    "print('The worst 3 IOs for LEVEL_01_170PPM_ADCRWB')\n",
    "cf.rwb_overlay_levels_nqplot(rwb_T0_sorted_by_level01window.iloc[-3:], groupby_col='IO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also plot the same data overlaying the previously plotted IOs grouped by level\n",
    "\n",
    "# Find the best and worst 3 IOs\n",
    "IOs = list(rwb_T0_sorted_by_level01window.iloc[:3].IO) + list(rwb_T0_sorted_by_level01window.iloc[-3:].IO)\n",
    "\n",
    "# Generate plot\n",
    "cf.rwb_groupby_level_nqplot(rwb_T0_sorted_by_level01window.loc[rwb_T0_sorted_by_level01window.IO.isin(IOs)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see from the figure above that the main differentiator for level 0/1 window is the tail formation in level1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have a rough handle for the appearance of the raw data, we can now examine IO-level correlations. Let's first look at RAC vs. the same T0 window metric\n",
    "\n",
    "# This function pivots the RWB table by TEST_NAME by grouping die/macro/IO information and splitting all data columns by unique TEST_NAMEs\n",
    "rwb_RAC_split = cf.rwb_pivot_by_test(rwb_RAC)\n",
    "\n",
    "# Plot scatter plots of various T0 metrics vs. post-bake metrics to explore which ones generate the best fit\n",
    "cf.rwb_scatter_plot(rwb_RAC_split, x='T0_read0 - LEVEL_01_XPOINT_PPM', y='150C220minbake_read0 - LEVEL_01_XPOINT_PPM', overlay_var='DIE_ID', fit_type='linear')\n",
    "cf.rwb_scatter_plot(rwb_RAC_split, x='T0_read0 - LEVEL_01_170PPM_ADCRWB', y='150C220minbake_read0 - LEVEL_01_XPOINT_PPM', overlay_var='DIE_ID', fit_type='linear')\n",
    "cf.rwb_scatter_plot(rwb_RAC_split, x='T0_read0 - LEVEL_0_0ADC_PPM', y='150C220minbake_read0 - LEVEL_01_XPOINT_PPM', overlay_var='DIE_ID', fit_type='linear')\n",
    "cf.rwb_scatter_plot(rwb_RAC_split, x='T0_read0 - LEVEL_1_DISTSIGMA', y='150C220minbake_read0 - LEVEL_01_XPOINT_PPM', overlay_var='DIE_ID', fit_type='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Bit-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The follow code snippet it used to fetch bit-level data for further deep dive. For isntance let's pull the bit level data for the 3 best and 3 worst IOs we found earlier\n",
    "\n",
    "# Create a dataframe of just the rows of interest, don't pull too much data (no more than 20 unique readouts) since it will be slow to process\n",
    "rwb_bestandworstIOs = rwb_RAC.loc[(rwb_RAC.IO.isin([35,2]))&(rwb_RAC.TEST_NAME.isin(['T0_read0','pst100cycft_read0','150C220minbake_read0']))]\n",
    "\n",
    "# Fetch the raw bit-level data, each row is a unique die/macro/io/BL/WL and each coulmn is grouped by TEST_NAME  \n",
    "df_bit_level = cf.rwb_fetch_bitlevel_data(rwb_bestandworstIOs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first ten rows of bit level data\n",
    "df_bit_level.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to csv file for further analysis\n",
    "df_bit_level.to_csv('bit_level_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I haven't gotten a chance to write functions that plot bit-level data in python yet, currently using JMP for this type of analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
